{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26c3976-adcf-46cc-bdc6-abf7905aee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e94e12-ba6a-45a9-872a-6035a7520ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc92be-5e5f-4024-b115-c15f207b2f4e",
   "metadata": {},
   "source": [
    "# Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ee70b3-4c52-4a43-96ff-8e53378bbc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db26c71-fbe2-4c50-a908-b26ce64323c7",
   "metadata": {},
   "source": [
    "# Chat Models: GPT-3.5 Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3946ed01-14b5-48eb-8e3e-a8744072d2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is the branch of physics that studies the behavior of particles and energy at the smallest scales, where phenomena such as superposition, entanglement, and wave-particle duality occur.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.')\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566dfb4-0dc4-40e7-9243-fdd4d0180f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ChatOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1069125f-89fc-4bd7-8907-26c4b148510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf atomarer und subatomarer Skala durch Wellenfunktionen und Wahrscheinlichkeitsverteilungen.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import(\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content= 'You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd5be4-8f68-4136-b98e-a27c5b8e6550",
   "metadata": {},
   "source": [
    "# Caching LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18734fe8-e711-4cc3-9c0b-0dc47bfeb97b",
   "metadata": {},
   "source": [
    "## In-Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ec0a3f-a88c-4dc6-ba2f-a26fdb7edede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "llm  = OpenAI(model_name = 'gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379ed965-5bf6-44b3-82bd-7505a3875b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 21.2 ms, total: 1.04 s\n",
      "Wall time: 1.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Why did the tomato turn red?\" \\n\"Because it saw the salad dressing!\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = 'Tell me a joke a toddler can understand'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c0ae33-cc13-493e-9ad5-46a4240152f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 334 μs, sys: 28 μs, total: 362 μs\n",
      "Wall time: 368 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Why did the tomato turn red?\" \\n\"Because it saw the salad dressing!\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bfbec-ce18-4173-9b5a-08233b24149d",
   "metadata": {},
   "source": [
    "## SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cadfd38-7607-4a8a-87f6-3b2ab19eab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path = '.langchain.db'))\n",
    "prompt = 'Tell me a joke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3aeea5a-c0da-4b91-9490-2a5ffd5f6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 503 μs, total: 14.5 ms\n",
      "Wall time: 1.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the tomato turn red?\\n\\nBecause it saw the salad dressing!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First request. It will not be cached.\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100fd095-db56-4201-9fc7-9cecbb0fd34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 145 μs, total: 1.8 ms\n",
      "Wall time: 1.79 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the tomato turn red?\\n\\nBecause it saw the salad dressing!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Second request is faster since the response is cached.\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e188d-07be-4f08-bb5b-247a7da85c19",
   "metadata": {},
   "source": [
    "# LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee3301-b085-48a4-bf60-d6b60f3bc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end = '', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d785ee4-1135-45f7-9ca7-36d788ac12ac",
   "metadata": {},
   "source": [
    "# PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079255f-80f0-4e82-8916-59f0978220ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experience virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "prompt = prompt_template.format(virus = 'hiv', language = 'german')\n",
    "\n",
    "llm = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0)\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac536f-240c-4f03-a440-948f21b8d84f",
   "metadata": {},
   "source": [
    "# ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34796570-18f7-422f-a0c2-8d2db9fcc571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format', additional_kwargs={}, response_metadata={}), HumanMessage(content='Top 10 countries in Europe by population.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content = 'You respond only in the JSON format'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=10, area = 'Europe')\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb737681-76e6-4a51-8e06-d48e9d760c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(message)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e17401-8efa-43ea-9136-5e41c7fe9fa7",
   "metadata": {},
   "source": [
    "# Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2aad44-ed39-4172-a8c8-aa1aeab824cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El virus del herpes simple (HSV) es un patógeno común que afecta a millones de personas en todo el mundo. Se transmite principalmente a través del contacto directo con lesiones activas, como ampollas, en la piel o las membranas mucosas. El HSV puede causar una serie de afecciones, como herpes labial, herpes genital y en casos graves, encefalitis herpética. Afortunadamente, existen tratamientos antivirales que pueden ayudar a controlar los síntomas y prevenir la recurrencia de las infecciones por HSV.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "template = '''You are an experience virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({'virus': 'HSV', 'language': ' Spanish'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7251efca-a3bc-45c7-a35f-d56cdae6f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter country:  Peru\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Peru is Lima.\n",
      "\n",
      "Top 3 places to visit in Peru:\n",
      "\n",
      "- Machu Picchu\n",
      "- Cusco\n",
      "- The Amazon Rainforest\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}? List the top 3 places to visit in that country. Use bullet points'\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "country = input('Enter country: ')\n",
    "output = chain.invoke(country)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ebc25-8e4d-4e2a-9cc0-f54f460d68da",
   "metadata": {},
   "source": [
    "# Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9283ba58-177a-4265-a493-506dae34796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure, here is a simple implementation of linear regression in Python:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def linear_regression(x, y):\n",
      "    n = len(x)\n",
      "    x_mean = np.mean(x)\n",
      "    y_mean = np.mean(y)\n",
      "    \n",
      "    numerator = 0\n",
      "    denominator = 0\n",
      "    for i in range(n):\n",
      "        numerator += (x[i] - x_mean) * (y[i] - y_mean)\n",
      "        denominator += (x[i] - x_mean) ** 2\n",
      "    \n",
      "    slope = numerator / denominator\n",
      "    intercept = y_mean - slope * x_mean\n",
      "    \n",
      "    return slope, intercept\n",
      "\n",
      "# Example usage\n",
      "x = np.array([1, 2, 3, 4, 5])\n",
      "y = np.array([2, 3, 4, 5, 6])\n",
      "\n",
      "slope, intercept = linear_regression(x, y)\n",
      "print(f\"Slope: {slope}, Intercept: {intercept}\")\n",
      "```\n",
      "\n",
      "This function calculates the slope and intercept of the linear regression line that best fits the given data points `(x, y)`. You can use this function with your own data by passing in arrays of x and y values.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe given Python function `linear_regression` calculates the parameters (slope and intercept) of the line that best fits a set of data points in a two-dimensional space, using a statistical method known as simple linear regression. This method aims to model the relationship between a dependent variable `y` and an independent variable `x` through a linear equation of the form:\n",
      "\n",
      "\\[ y = m \\cdot x + b \\]\n",
      "\n",
      "where:\n",
      "- \\(m\\) is the slope of the line, representing how much \\(y\\) changes for a one-unit change in \\(x\\).\n",
      "- \\(b\\) is the intercept, indicating the value of \\(y\\) when \\(x = 0\\).\n",
      "\n",
      "The essence of simple linear regression is to find the line that minimises the sum of the squared vertical distances (errors) of the data points from the line.\n",
      "\n",
      "The function implementation involves several steps outlined below:\n",
      "\n",
      "1. **Import Required Module**: The `numpy` module is imported with the nickname `np`. `numpy` is a fundamental package for scientific computing in Python, providing support for arrays, mathematical functions, random number generation, and more.\n",
      "\n",
      "2. **Function Definition**: The `linear_regression(x, y)` function accepts two arguments:\n",
      "   - `x`: a numpy array of the independent variable data points.\n",
      "   - `y`: a numpy array of the dependent variable data points.\n",
      "\n",
      "3. **Variable Initialization**:\n",
      "   - `n` calculates the number of data points by getting the length of the `x` array.\n",
      "   - `x_mean` computes the mean (average) value of the `x` data points using `np.mean`.\n",
      "   - `y_mean` computes the mean value of the `y` data points in a similar fashion.\n",
      "\n",
      "4. **Slope Calculation**:\n",
      "   - The function then initializes two variables, `numerator` and `denominator`, to zero. These variables will store the cumulative values used to calculate the slope (`m`).\n",
      "   - A loop iterates over each data point, updating `numerator` by adding the product of the difference between each `x` value and `x_mean` with the difference between the corresponding `y` value and `y_mean`.\n",
      "   - The `denominator` is updated by adding the square of the difference between each `x` value and `x_mean`.\n",
      "   - After completing the loop, the slope `m` is calculated by dividing `numerator` by `denominator`.\n",
      "\n",
      "5. **Intercept Calculation**:\n",
      "   - The intercept (`b`) is calculated by subtracting the product of the slope and `x_mean` from `y_mean`.\n",
      "\n",
      "6. **Return Values**:\n",
      "   - The function returns the calculated `slope` and `intercept` which can be used to define the best fit line for the given data points.\n",
      "\n",
      "7. **Example Usage**:\n",
      "   - An example usage of the `linear_regression` function is provided, where it is used to compute the slope and intercept for a given set of x and y numpy arrays.\n",
      "   - The output is printed to the console, showing the calculated slope and intercept for the example data.\n",
      "\n",
      "This implementation of linear regression is a straightforward example of fitting a linear equation to a set of points. It demonstrates the calculations essential for linear regression without using advanced optimization functions available in libraries like `scipy` or machine learning frameworks. The method used here is specifically intended for educational purposes to understand the principles behind linear regression. In practice, for large datasets or more complex models, one would likely use specialized libraries that offer optimized algorithms and additional functionalities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template = 'You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "\n",
    "# chain1 = prompt_template1 | llm1 | StrOutputParser()\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
    "\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template = 'Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "\n",
    "# chain2 = prompt_template2 | llm2 | StrOutputParser()\n",
    "\n",
    "chain2 = LLMChain(llm=llm2, prompt = prompt_template2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains = [chain1, chain2], verbose=True)\n",
    "\n",
    "output = overall_chain.invoke('linear regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582489b-40c8-4d5e-b79e-79dc5a4e265e",
   "metadata": {},
   "source": [
    "# LangChain Agents in Action: Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a6cb3a8-0e02-4f1a-b5db-72d937d9afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1,100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01a5e07a-a188-4228-ab3e-9dc6527245b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve this, I will first calculate the factorial of 12 using the `math` module's `factorial` function. Then, I will calculate the square root of that result using the `sqrt` function from the same module. Finally, I will format the result to display it with 4 decimal points using the `format` function.\n",
      "Action: Python_REPL\n",
      "Action Input: import math\n",
      "print(format(math.sqrt(math.factorial(12)), '.4f'))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 21886.1052\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points.',\n",
       " 'output': '21886.1052'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4-turbo-preview', temperature=0)\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm = llm,\n",
    "    tool = PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke('Calculate the square root of the factorial of 12 and display it with 4 decimal points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0df4847c-0dba-41c9-a298-22df130d1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI will calculate the power of 5.1 raised to 7.3 using Python.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke('What is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627d500-e32c-4957-a71d-e36ca9583334",
   "metadata": {},
   "source": [
    "# LangChain Tools: DuckDuckGo and Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba4a787-be7e-4b4e-8bc2-4e51e3100b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eab3494-ebe0-4234-9494-d7d323561812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: duckduckgo_search\n",
      "Version: 7.3.0\n",
      "Summary: Search for words, documents, images, news, maps and text translation using the DuckDuckGo.com search engine.\n",
      "Home-page: \n",
      "Author: deedy5\n",
      "Author-email: \n",
      "License: MIT License\n",
      "Location: /home/marcelo/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages\n",
      "Requires: click, lxml, primp\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017c6460-2ea7-463e-9b0c-42a4722a0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freddie Mercury, born Farrokh Bulsara on September 5, 1946, in Zanzibar, was a legendary singer-songwriter and the charismatic frontman of the rock band Queen. With a unique background as a Parsi in Tanzania and a music education in India, Mercury made a significant impact on the music world. But there are many lesser-known Freddie Mercury facts that reveal hidden depths to the life and work of the man born Farrokh Bulsara in Zanzibar, on September 5, 1946. Freddie Mercury was born Farrokh Bulsara on September 5, 1946, in Stone Town, Zanzibar. His early years in the vibrant island city were influenced by its diverse culture and rich history. His parents, Bomi and Jer Bulsara, were Parsi, and they hailed from India. This multicultural environment played a significant role in shaping Mercury's ... Freddie Mercury was born Farrokh Bulsara in Stone Town in the British protectorate of the Sultanate of Zanzibar, East Africa (now part of Tanzania) on September 5, 1946. When did he get his start in music? Freddie Mercury began his musical career in the late 1960s. He formed his first band, The Hectics, while attending St. Peter's School in ... Freddie Mercury, born Farrokh Bulsara on September 5, 1946, in Stone Town, Zanzibar (now part of Tanzania), was a British singer, songwriter, and record producer. Renowned as the flamboyant frontman of the rock band Queen, Mercury's powerful vocals and dynamic stage presence cemented his status as one of rock music's most iconic figures.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.invoke('Where was Freddie Mercury born?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178d4025-7693-4dc7-9e8f-cb8e8cd8b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckduckgo_search'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7991d996-0bc8-4fb0-b85b-772d34fa83f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1d3e6b-0b39-4c9b-8047-8190495cc1a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DuckDuckGoSearchException",
     "evalue": "https://html.duckduckgo.com/html 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDuckDuckGoSearchException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DuckDuckGoSearchResults\n\u001b[32m      3\u001b[39m search = DuckDuckGoSearchResults()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m output = \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFreddie Mercury and Queen\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/langchain_core/tools/base.py:763\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    762\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    764\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    765\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/langchain_core/tools/base.py:732\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    731\u001b[39m     tool_kwargs = tool_kwargs | {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/langchain_community/tools/ddg_search/tool.py:112\u001b[39m, in \u001b[36mDuckDuckGoSearchResults._run\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    108\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    109\u001b[39m     run_manager: Optional[CallbackManagerForToolRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    110\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Union[List[\u001b[38;5;28mdict\u001b[39m], \u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mdict\u001b[39m]]:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     raw_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     results = [\n\u001b[32m    116\u001b[39m         {\n\u001b[32m    117\u001b[39m             k: v\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m raw_results\n\u001b[32m    122\u001b[39m     ]\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_format == \u001b[33m\"\u001b[39m\u001b[33mlist\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/langchain_community/utilities/duckduckgo_search.py:146\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper.results\u001b[39m\u001b[34m(self, query, max_results, source)\u001b[39m\n\u001b[32m    142\u001b[39m source = source \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    144\u001b[39m     results = [\n\u001b[32m    145\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m: r[\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: r[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mlink\u001b[39m\u001b[33m\"\u001b[39m: r[\u001b[33m\"\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ddgs_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     ]\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mnews\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     results = [\n\u001b[32m    150\u001b[39m         {\n\u001b[32m    151\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m: r[\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ddgs_news(query, max_results=max_results)\n\u001b[32m    158\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/langchain_community/utilities/duckduckgo_search.py:64\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[39m\u001b[34m(self, query, max_results)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mduckduckgo_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DDGS\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     ddgs_gen = \u001b[43mddgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ddgs_gen:\n\u001b[32m     73\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ddgs_gen]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git/MarceloLeite2604/langchain-and-pinecone-course/venv/lib/python3.11/site-packages/duckduckgo_search/duckduckgo_search.py:292\u001b[39m, in \u001b[36mDDGS.text\u001b[39m\u001b[34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[39m\n\u001b[32m    289\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError to search using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    290\u001b[39m         err = ex\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m DuckDuckGoSearchException(err)\n",
      "\u001b[31mDuckDuckGoSearchException\u001b[39m: https://html.duckduckgo.com/html 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run('Freddie Mercury and Queen')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff17ffe1-e70c-4b15-9627-275e962aca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: Berlin [bɛr'li:n] ist die Hauptstadt [12] und ein Land der Bundesrepublik Deutschland. [13] [14] Die Großstadt ist mit rund 3,7 Millionen Einwohnern [15] die bevölkerungsreichste und mit 891 Quadratkilometern die flächengrößte Gemeinde Deutschlands sowie die bevölkerungsreichste Stadt der Europäischen Union. [4], title: Berlin - Wikipedia, link: https://de.wikipedia.org/wiki/Berlin, snippet: Zeitgenössische Kunst, Malerei, Grafik, Fotografie oder Skulptur: Berlin ist die Stadt für alle Künste! Eine Auswahl aufregender Ausstellungen in Berliner Museen und Galerien., title: Ausstellungen in Berlin - Berlin.de, link: https://www.berlin.de/ausstellungen/, snippet: Über 10.000 Tips in mehr als 20 Kategorien bieten besondere Erlebnisse, originelle Ideen, außergewöhnliche Events und (neue) spannende Entdeckungen für Berliner, aber auch Berlin-Besucher, die sich auf ein etwas anderes Städtereise-Wochenende in Berlin freuen., title: Gratis in Berlin - Tipps für tolle Events und Veranstaltungen, link: https://www.gratis-in-berlin.de/, snippet: Immer wieder eine Reise wert: Berlin ist im ständigen Wandel. Die Highlights und Neuheiten zwischen Ku'damm und Alexanderplatz, mit Karte. Die besten Aussichtsplätze und Sightseeing-Touren. Auf den Spuren der Berliner Mauer. Grünes Berlin am Tempelhofer Feld und im Park am Gleisdreieck, title: 20 Sehenswürdigkeiten in Berlin: Die besten Tipps für 2025 - ADAC, link: https://www.adac.de/reise-freizeit/reiseplanung/inspirationen/deutschland/sehenswuerdigkeiten-berlin/\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region = 'de-de', max_results = 3, safesearch = 'moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper = wrapper, source = 'news')\n",
    "output = search.run('Berlin')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc1cf98-f93a-4a46-9150-893b3398c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: Berlin [bɛr'li:n] ist die Hauptstadt [12] und ein Land der Bundesrepublik Deutschland. [13] [14] Die Großstadt ist mit rund 3,7 Millionen Einwohnern [15] die bevölkerungsreichste und mit 891 Quadratkilometern die flächengrößte Gemeinde Deutschlands sowie die bevölkerungsreichste Stadt der Europäischen Union. [4], title: Berlin - Wikipedia, link: https://de.wikipedia.org/wiki/Berlin, snippet: Zeitgenössische Kunst, Malerei, Grafik, Fotografie oder Skulptur: Berlin ist die Stadt für alle Künste! Eine Auswahl aufregender Ausstellungen in Berliner Museen und Galerien., title: Ausstellungen in Berlin - Berlin.de, link: https://www.berlin.de/ausstellungen/, snippet: Über 10.000 Tips in mehr als 20 Kategorien bieten besondere Erlebnisse, originelle Ideen, außergewöhnliche Events und (neue) spannende Entdeckungen für Berliner, aber auch Berlin-Besucher, die sich auf ein etwas anderes Städtereise-Wochenende in Berlin freuen., title: Gratis in Berlin - Tipps für tolle Events und Veranstaltungen, link: https://www.gratis-in-berlin.de/, snippet: Immer wieder eine Reise wert: Berlin ist im ständigen Wandel. Die Highlights und Neuheiten zwischen Ku'damm und Alexanderplatz, mit Karte. Die besten Aussichtsplätze und Sightseeing-Touren. Auf den Spuren der Berliner Mauer. Grünes Berlin am Tempelhofer Feld und im Park am Gleisdreieck, title: 20 Sehenswürdigkeiten in Berlin: Die besten Tipps für 2025 - ADAC, link: https://www.adac.de/reise-freizeit/reiseplanung/inspirationen/deutschland/sehenswuerdigkeiten-berlin/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)\\],'\n",
    "matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "for snippet, title, link in matches:\n",
    "    print(f'Snippet: {snippet},\\nTitle: {title}\\nLink: {link}\\n')\n",
    "    print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
