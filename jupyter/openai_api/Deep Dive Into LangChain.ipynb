{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c3976-adcf-46cc-bdc6-abf7905aee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e94e12-ba6a-45a9-872a-6035a7520ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc92be-5e5f-4024-b115-c15f207b2f4e",
   "metadata": {},
   "source": [
    "# Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee70b3-4c52-4a43-96ff-8e53378bbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db26c71-fbe2-4c50-a908-b26ce64323c7",
   "metadata": {},
   "source": [
    "# Chat Models: GPT-3.5 Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946ed01-14b5-48eb-8e3e-a8744072d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.')\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566dfb4-0dc4-40e7-9243-fdd4d0180f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ChatOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069125f-89fc-4bd7-8907-26c4b148510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content= 'You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd5be4-8f68-4136-b98e-a27c5b8e6550",
   "metadata": {},
   "source": [
    "# Caching LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18734fe8-e711-4cc3-9c0b-0dc47bfeb97b",
   "metadata": {},
   "source": [
    "## In-Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec0a3f-a88c-4dc6-ba2f-a26fdb7edede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "llm  = OpenAI(model_name = 'gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ed965-5bf6-44b3-82bd-7505a3875b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = 'Tell me a joke a toddler can understand'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0ae33-cc13-493e-9ad5-46a4240152f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bfbec-ce18-4173-9b5a-08233b24149d",
   "metadata": {},
   "source": [
    "## SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadfd38-7607-4a8a-87f6-3b2ab19eab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path = '.langchain.db'))\n",
    "prompt = 'Tell me a joke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aeea5a-c0da-4b91-9490-2a5ffd5f6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First request. It will not be cached.\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fd095-db56-4201-9fc7-9cecbb0fd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Second request is faster since the response is cached.\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e188d-07be-4f08-bb5b-247a7da85c19",
   "metadata": {},
   "source": [
    "# LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee3301-b085-48a4-bf60-d6b60f3bc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end = '', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d785ee4-1135-45f7-9ca7-36d788ac12ac",
   "metadata": {},
   "source": [
    "# PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079255f-80f0-4e82-8916-59f0978220ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experience virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "prompt = prompt_template.format(virus = 'hiv', language = 'german')\n",
    "\n",
    "llm = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0)\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac536f-240c-4f03-a440-948f21b8d84f",
   "metadata": {},
   "source": [
    "# ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34796570-18f7-422f-a0c2-8d2db9fcc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content = 'You respond only in the JSON format'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=10, area = 'Europe')\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb737681-76e6-4a51-8e06-d48e9d760c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(message)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e17401-8efa-43ea-9136-5e41c7fe9fa7",
   "metadata": {},
   "source": [
    "# Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2aad44-ed39-4172-a8c8-aa1aeab824cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "template = '''You are an experience virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({'virus': 'HSV', 'language': ' Spanish'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251efca-a3bc-45c7-a35f-d56cdae6f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'What is the capital of {country}? List the top 3 places to visit in that country. Use bullet points'\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "country = input('Enter country: ')\n",
    "output = chain.invoke(country)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ebc25-8e4d-4e2a-9cc0-f54f460d68da",
   "metadata": {},
   "source": [
    "# Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283ba58-177a-4265-a493-506dae34796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template = 'You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "\n",
    "# chain1 = prompt_template1 | llm1 | StrOutputParser()\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
    "\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template = 'Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "\n",
    "# chain2 = prompt_template2 | llm2 | StrOutputParser()\n",
    "\n",
    "chain2 = LLMChain(llm=llm2, prompt = prompt_template2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains = [chain1, chain2], verbose=True)\n",
    "\n",
    "output = overall_chain.invoke('linear regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582489b-40c8-4d5e-b79e-79dc5a4e265e",
   "metadata": {},
   "source": [
    "# LangChain Agents in Action: Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cb3a8-0e02-4f1a-b5db-72d937d9afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1,100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5e07a-a188-4228-ab3e-9dc6527245b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4-turbo-preview', temperature=0)\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm = llm,\n",
    "    tool = PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke('Calculate the square root of the factorial of 12 and display it with 4 decimal points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4847c-0dba-41c9-a298-22df130d1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke('What is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627d500-e32c-4957-a71d-e36ca9583334",
   "metadata": {},
   "source": [
    "# LangChain Tools: DuckDuckGo and Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4a787-be7e-4b4e-8bc2-4e51e3100b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab3494-ebe0-4234-9494-d7d323561812",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c6460-2ea7-463e-9b0c-42a4722a0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.invoke('Where was Freddie Mercury born?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d4025-7693-4dc7-9e8f-cb8e8cd8b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991d996-0bc8-4fb0-b85b-772d34fa83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d3e6b-0b39-4c9b-8047-8190495cc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run('Freddie Mercury and Queen')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17ffe1-e70c-4b15-9627-275e962aca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region = 'de-de', max_results = 3, safesearch = 'moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper = wrapper, source = 'news')\n",
    "output = search.run('Berlin')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1cf98-f93a-4a46-9150-893b3398c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?),'\n",
    "matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "for snippet, title, link in matches:\n",
    "    print(f'Snippet: {snippet}\\nTitle: {title}\\nLink: {link}\\n')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a236e09-2489-4569-88c7-c7276c3394f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37189a7-3e9c-4ce7-b930-aec8da6d20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper = api_wrapper)\n",
    "wiki.invoke({'query': 'llamaindex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c83f1-7ec7-4c63-b782-22de35a2ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.invoke('Google Gemini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60da13-3bd8-458b-b920-47501e92eb7d",
   "metadata": {},
   "source": [
    "# Creating a ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41336fb9-7046-464b-8256-6cf492e6a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9a050-633e-45ef-8941-25b5f0903aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61bfa3-741f-4482-943c-dd76e60c57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name = 'gpt-4-turbo-preview', temperature=0)\n",
    "\n",
    "# template='''\n",
    "# Answer the following questions as best as you can.\n",
    "# Questions: {q}\n",
    "# '''\n",
    "\n",
    "template='''\n",
    "Answer the following questions in Brazilian Portuguese as best as you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "# print(type(prompt))\n",
    "# print(prompt.input_variables)\n",
    "# print(prompt.template)\n",
    "\n",
    "# 1. Python REPL tool (for execute Python code)\n",
    "\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "python_repl_tool = Tool(\n",
    "    name = 'Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to use Python to answer a question. You should input Python code.'\n",
    ")   \n",
    "\n",
    "# 2. Wikipedia tool (for searching Wikipedia)\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper = api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for when you need to look up a topic, country, or person on Wikipedia.'\n",
    ")\n",
    "\n",
    "# 3. DuckDuckGo Search Tool (for general web searches)\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool= Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Useful for when you need to perform an internet search to find information that another tool can\\'t provide.'\n",
    ")\n",
    "\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad9efb-5099-41fe-a587-2a9dc313b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Generate the first 20 numbers in the Fibonacci series.'\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71a18b-91af-4fc7-8361-c1ebc366f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eecd4e8-601e-430f-ae93-1583f8208b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79cde20-2f21-4540-aa4b-c91f91aa765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Who is the current prime minister of the UK?'\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e531c5-65a8-45c9-821b-1af8c55b17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What are the latest Brazilian football news?'\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129532b-83a0-4f8c-b37f-5ecb6a1dcede",
   "metadata": {},
   "source": [
    "# Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a827497-9bdf-43e3-a616-7b6431abc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364345d-2985-4fd3-b835-4728540941b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b29af0-b50c-4b14-ad5b-2071cb6b4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade -q pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913f656-adfc-4c42-8659-c7506e3a5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f978daf-3b36-4368-be8f-99f9a1c14ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone()\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4a967-7307-4686-89aa-6f83d5386fae",
   "metadata": {},
   "source": [
    "# Working with Pinecone Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a64b4e-6515-4727-8f50-c7fba279f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb0de1-4ab5-448d-9efa-54c7eedf799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b92e0-03b9-4d8b-9ce2-eeadb2e78b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f'Creating index: {index_name}', flush=True)\n",
    "    pc.create_index(\n",
    "        name = index_name, \n",
    "        dimension = 1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('Index created.')\n",
    "else:\n",
    "    print(f'Index {index_name} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbd80a-ea7c-4a33-be34-322869455d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'langchain'\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    print(f'Deleting index {index_name}...')\n",
    "    pc.delete_index(index_name)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print(f'Index {index_name} does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa874a51-def9-4e2a-9e1b-e6fb18ed9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7187a-3859-4b61-b8dd-a1f09ae4c82e",
   "metadata": {},
   "source": [
    "# Working with Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45871408-8675-4c1f-a52d-e2e64c188432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "vectors = [[random.random() for _ in range(1536)] for v in range(5)]\n",
    "# print(vectors)\n",
    "ids = list('abcde')\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "index.upsert(vectors = zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbfa2ff-70ba-4203-972e-5012dbedaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating vectors\n",
    "index.upsert(vectors=[('c', [0.5]*1536)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04876a-1d83-4277-9a3e-92624ee3ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching vectors\n",
    "index = pc.Index(index_name)\n",
    "index.fetch(ids=['c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd086ea-fab4-4f09-9ebe-96499270f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting vectors\n",
    "index.delete(ids=['b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fa691-e869-40be-ab1d-3254efb4c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da246fdd-9503-4aea-8583-fb3faa73b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fetch(ids=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc33ce4-37f7-41c9-9593-e06f97beb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "query_vector = [ random.random() for _ in range(1536)]\n",
    "\n",
    "index.query(\n",
    "    vector = query_vector,\n",
    "    top_k = 3,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639c9e8-6fa6-43ab-8018-386c1f7c85ff",
   "metadata": {},
   "source": [
    "# Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305516fa-a485-41ca-a695-f998b70a078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectors = [[random.random() for _ in range(1536)] for v in range(5)]\n",
    "# print(vectors)\n",
    "ids = list('abcde')\n",
    "\n",
    "index.upsert(vectors = zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fddad-867b-49b7-8042-603a9d4ad684",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[random.random() for _ in range(1536)] for v in range(3)]\n",
    "# print(vectors)\n",
    "ids = list('xyz')\n",
    "\n",
    "index.upsert(vectors = zip(ids, vectors), namespace='first-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc515f-f37f-404a-950f-6919ba327e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[random.random() for _ in range(1536)] for v in range(2)]\n",
    "# print(vectors)\n",
    "ids = list('qp')\n",
    "\n",
    "index.upsert(vectors = zip(ids, vectors), namespace='second-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b25e3-3038-4274-ba71-a576d9d15588",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82f344-23a0-43f7-aa89-b1a675306127",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fetch(ids=['x'], namespace='first-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd4c67-5d5f-4efc-a0f2-bf9bde819fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.delete(ids=['x'], namespace='first-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c405e-50a1-4eff-b9bd-ee9497db60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.delete(delete_all=True, namespace='first-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5744b-9301-4ab9-ae53-3b735f2e3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0bfad-e422-4755-b195-7854b2873f51",
   "metadata": {},
   "source": [
    "# Splitting and Embedding Text Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f308e29-eaca-492f-9310-b5081adc97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb5ced-a9bd-4c2f-bdd3-b9824e3c6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('files/churchill_speech.txt') as f:\n",
    "    churchill_speech = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f475bac-32d1-46bb-86eb-e44a65a5908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents([churchill_speech])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055086f8-f683-498e-b14d-db0fa2d9b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chunks[0].page_content)\n",
    "# print(chunks[1].page_content)\n",
    "print(f'Now you have {len(chunks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a29f9b-7251-4f85-80ca-3638d3ad8781",
   "metadata": {},
   "source": [
    "## Embedding Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ebbd7-ec78-45be-a551-589afdb1014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000 * 0.0004:.6f}')\n",
    "\n",
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2427af-20b9-47ef-a61f-92162738e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c87cc-dbe6-4437-a76e-c537949b07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embeddings.embed_query(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf032ecf-8354-426f-aecf-36b40bd94983",
   "metadata": {},
   "source": [
    "# Inserting the Embeddings into a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b5940-25cf-46a5-a42c-4f1d888a1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320efd3-8715-4598-927f-8de4b12cb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad4820-a771-4a9f-9408-c09db0d1b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "from pinecone.data.index import Index\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "pc = pinecone.Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87329f8-76e3-4cbf-b715-4ac0a7b8b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in pc.list_indexes().names():\n",
    "#     print('Deleting all indexes... ', end='', flush=True)\n",
    "#     pc.delete_index(i)\n",
    "#     print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac451c29-82d8-4c58-98c4-b3df8d849aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'churchill-speech'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f'Creating index {index_name}...', end='', flush=True)\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536,\n",
    "    metric='cosine',\n",
    "    spec=pinecone.ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    print('done.')\n",
    "else:\n",
    "    print(f'Index {index_name} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e18ed-4afe-429b-80b1-5c2b93504cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_documents(chunks, embeddings, index_name = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be1537-b16b-4e9c-a748-e733a73c5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_existing_index(index_name = 'churchill-speech', embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbb624-083d-4dd6-b287-5a5fe4a96a9d",
   "metadata": {},
   "source": [
    "# Asking Questions (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e6c03-9a12-40a5-85e1-c62e4b13e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Where should we fight?'\n",
    "result = vector_store.similarity_search(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1d6fd-83be-4e9f-bb84-f742713b1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea01fb-d85d-4972-8ddc-4a77ffd6c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a916040-b6c3-45bb-85e4-f8372bdd0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = 'Where should we fight?'\n",
    "# query = 'Who was the king of Belgium at that time?'\n",
    "query = 'What about the French Armies?'\n",
    "answer = chain.invoke(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
